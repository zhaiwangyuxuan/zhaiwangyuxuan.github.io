Please refer to my [Google Scholar](https://scholar.google.com/citations?user=KtNShhoAAAAJ).
è¯·å‚è€ƒæˆ‘çš„ [è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=KtNShhoAAAAJ).

### ç¬¬ä¸€ä½œè€…è®ºæ–‡ Sole First Author Paper

- None ğŸ˜­ğŸ˜­ğŸ˜­

### å…±åŒä¸€ä½œè®ºæ–‡ Co-First Author Paper

- *X. Wang\*, Z. Kang\*, <strong><strong>W. Zhai\*</strong></strong>, X. Lou, Y. Lai, Z. Wang, Y. Wang, K. Huang, Y. Wang, P. Li, Y. Liu. (2025). MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models. <strong><strong>EMNLP 2025 Main Conference</strong></strong>.* [[Paper]](https://arxiv.org/abs/2506.17046)

### å…¶ä»–è®ºæ–‡ Other Paper

- *L. Yuan\*, F. Mo\*, K. Huang, W. Wang, <strong><strong>W. Zhai</strong></strong>, X. Zhu, Y. Li, J. Xu, J.-Y. Nie. (2025). OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence. arXiv Preprint.*[[Paper]](https://arxiv.org/abs/2503.16326)

<!-- - <strong><strong>*C. Yin</strong></strong>, E. Wei, Z. Zhang, Z. Zhan. (2025). PaperHelper: Knowledge-Based LLM QA Paper Reading Assistant. arXiv Preprint.*[[Paper]](https://arxiv.org/abs/2502.14271) -->

<!-- - *Y. Zhao, <strong><strong>C. Yin</strong></strong>, X. Tian, Y. Ge. (2024). FanLoRA: Fantastic LoRAs and Where to Find Them in Large Language Model Fine-tuning. Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing <strong><strong>(EMNLP 2024)</strong></strong>.*[[Paper]](https://aclanthology.org/2024.emnlp-industry.38.pdf)

- *W. Zhu, Y. Ni, <strong><strong>C. Yin</strong></strong>, A. Tian, X. Wang, G. Xie. (2024). IAPT: Instance-Aware Prompt Turing for Large Language Models. The 62nd Annual Meeting of the Association for Computational Linguistics <strong><strong>(ACL 2024)</strong></strong>.*[[Paper]](https://aclanthology.org/2024.acl-long.771.pdf)

- *X. Gao, W. Zhu, J. Gao and <strong><strong>C. Yin</strong></strong>. (2023). F-PABEE: Flexible-Patience-Based Early Exiting For Single-Label and Multi-Label Text Classification Tasks. 2023 IEEE International Conference on Acoustics, Speech and Signal Processing <strong><strong>(ICASSP 2023)</strong></strong>.* [[Paper]](https://ieeexplore.ieee.org/abstract/document/10095864)

- *<strong><strong>C. Yin</strong></strong>. (2023). Multi-scale and multi-task learning for human audio forensics based on convolutional networks. International Conference on Image, Signal Processing, and Pattern Recognition <strong><strong>(ISPP 2023)</strong></strong>.* [[Paper]](https://doi.org/10.1117/12.2681344) -->
