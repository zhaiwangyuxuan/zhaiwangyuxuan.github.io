
<!-- [![LinkedIn](https://img.shields.io/badge/LinkedIn-%230A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/jerry-yin-a21314292/) -->
[![GitHub](https://img.shields.io/badge/GitHub-%23121011?style=for-the-badge&logo=github&logoColor=white)](https://github.com/zhaiwangyuxuan)
[![Google Scholar](https://img.shields.io/badge/Google%20Scholar-%230A4D92?style=for-the-badge&logo=googlescholar&logoColor=white)](https://scholar.google.com/citations?user=KtNShhoAAAAJ)
<!-- [![çŸ¥ä¹](https://img.shields.io/badge/%E7%9F%A5%E4%B9%8E-%231E2A2A?style=for-the-badge&logo=zhihu&logoColor=blue)](https://www.zhihu.com/people/ycr222/posts) -->


#### News


* ğŸ‰ One of my papers, [MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models](https://arxiv.org/abs/2506.17046), has been accepted by the **EMNLP 2025 Main Conference**.

* ğŸ‰ æˆ‘çš„è®ºæ–‡ [MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models](https://arxiv.org/abs/2506.17046) å·²è¢« **2025å¹´EMNLPä¸»ä¼š** å½•ç”¨ã€‚

<!-- * <strong><strong> One of my papers 'MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models.' have been accepted by EMNLP 2025 Main Conference </strong></strong> 
* <strong><strong> æˆ‘çš„ä¸€ç¯‡è®ºæ–‡ 'MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models.' å·²è¢« 2025 å¹´ EMNLP ä¸»ä¼šå½•ç”¨ </strong></strong>  -->

<!-- * <strong style="color:red;"><strong>Iâ€™m actively looking for Machine Learning System and O1/MLLM/LLM Industrial/Research Opportunity.</strong></strong> <strong><strong>This includes</strong></strong> 
    * Train more powerful reasoning models like [DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1) and [QwQ](https://huggingface.co/Qwen/QwQ-32B-Preview). 
    * Improve RLHF training frameworks in the direction of reinforcement learning (such as [veRL](https://github.com/volcengine/verl) and [OpenRLHF](https://github.com/OpenRLHF/OpenRLHF)).
    * Develop robust inference frameworks like [SGLang](https://github.com/sgl-project/sglang).

If you need a reliable teammate who is familiar with <strong style="color:red;"><strong>both NLP and computer systems </strong></strong> with <strong style="color:red;"><strong>extensive industry experiences</strong></strong>, feel free to <a href="#contact-info">Contact Me</a>! -->


#### è‡ªæˆ‘ä»‹ç» Biography

æˆ‘å«ç¿Ÿç‹å®‡è½©ï¼Œæ˜¯åŒ—äº¬äº¤é€šå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢äººå·¥æ™ºèƒ½ä¸“ä¸šçš„æœ¬ç§‘ç”Ÿã€‚ç›®å‰ï¼Œæˆ‘åœ¨æœ¬æ ¡è·Ÿéš[å¾é‡‘å®‰](https://scholar.google.com/citations?user=wMuW0W4AAAAJ&hl=en)æ•™æˆå’Œ[é»„é”´å®‡](https://scholar.google.com/citations?user=qAp-hS4AAAAJ&hl=en)è€å¸ˆï¼Œå¼€å±• LLM ä¸åœ°ç†é¢†åŸŸäº¤å‰çš„ç›¸å…³ç ”ç©¶ ã€‚

åœ¨2025å¹´å¯’å‡æœŸé—´ï¼Œæˆ‘å‚åŠ äº†æ¸…å AIR çš„å†¬ä»¤è¥ã€‚åœ¨[æé¹](https://scholar.google.com/citations?hl=en&user=hgYzkOQAAAAJ)æ•™æˆçš„æŒ‡å¯¼ä¸‹ï¼Œæˆ‘æœ‰å¹¸å¾—åˆ°äº†æ¸…å AIR [ç‹æ™“é¾™](https://scholar.google.com/citations?hl=en&user=p0jarqgAAAAJ)å¸ˆå…„ä»¥åŠåŒ—å¤§è½¯å¾®[åº·å…†ç’](https://openreview.net/profile?id=~Zhaolu_Kang2)å¸ˆå§çš„å®è´µæŒ‡å¯¼ ã€‚

My name is Zhai Wangyuxuan, and I am an undergraduate student majoring in Artificial Intelligence at the School of Computer Science and Technology, Beijing Jiaotong University. Currently, under the supervision of Professor [Xu Jin'an](https://scholar.google.com/citations?user=wMuW0W4AAAAJ&hl=en) and Teacher [Huang Kaiyu](https://scholar.google.com/citations?user=qAp-hS4AAAAJ&hl=en) at my university, I am conducting research at the intersection of LLM and the field of geography.

During the winter vacation of 2025, I participated in the winter camp of Tsinghua AIR. Under the guidance of Professor [Li Peng](https://scholar.google.com/citations?hl=en&user=hgYzkOQAAAAJ), I was fortunate enough to receive valuable guidance from [Wang Xiaolong](https://scholar.google.com/citations?hl=en&user=p0jarqgAAAAJ) of Tsinghua AIR and [Kang Zhaolu]((https://openreview.net/profile?id=~Zhaolu_Kang2)) of Peking University Software and Microelectronics School.

#### ç ”ç©¶å…´è¶£ Research Interests

<!-- My current passion revolves around building **EFFICIENT** system solutions to AGI (<strong style="color:red;"><strong>Now I am interested in O1-like models ML Infra</strong></strong>), this includes: -->

- ç›®å‰ï¼Œæˆ‘çš„ä¸»è¦ç ”ç©¶é¢†åŸŸæ˜¯ <strong><strong> LLM / Agent  </strong></strong>ï¼›
- Currently, my main research area is **LLM / Agent**.

---

- åŒæ—¶ï¼Œæˆ‘ä¸ªäººè¿˜å¯¹<strong><strong> MIR (Music Information Retrieval) </strong></strong>ğŸ¶æ„Ÿå…´è¶£ã€‚
- Meanwhile, I am also interested in <strong><strong>MIR (Music Information Retrieval)</strong></strong>ğŸ¶.

#### æ•™è‚²ç»å† Education

ğŸ•’ **2023 å¹´ 9 æœˆ - è‡³ä»Š**  
ğŸ“ **åŒ—äº¬äº¤é€šå¤§å­¦**  
ğŸ“ **è®¡ç®—æœºå­¦é™¢ äººå·¥æ™ºèƒ½ä¸“ä¸š æœ¬ç§‘ç”Ÿ**  

ğŸ•’ **2023.9 - Present**  
ğŸ“ **Beijing Jiaotong University**  
ğŸ“ **Undergraduate Student in Artificial Intelligence, School of Computer Science**

#### æ‚é¡¹ Misc

- é™¤äº†ç ”ç©¶ä¹‹å¤–ï¼Œæˆ‘è¿˜æ˜¯ä¸€åéŸ³ä¹çˆ±å¥½è€…ã€‚æˆ‘ä¼šä¸€ç‚¹æ‰‹é£ç´ğŸª—ï¼Œæ›¾åœ¨ä¸­å¤®éŸ³ä¹å­¦é™¢å‚åŠ è¿‡ä¸šä½™è€ƒçº§ã€‚æˆ‘ä¹Ÿä¼šåˆ¶ä½œç”µå­éŸ³ä¹ğŸµï¼Œè‡ªå¨±è‡ªä¹è¶³çŸ£ã€‚

- æˆ‘æœ€å–œæ¬¢çš„æ¸¸æˆç±»å‹æ˜¯éŸ³ä¹æ¸¸æˆï¼Œç›®å‰æ­£çƒ­è¡·äºè¡—æœºéŸ³æ¸¸ã€ŠèˆèŒ DXã€‹ã€‚

- Beyond my research, I am enthusiastic about music. I play the accordionğŸª— and have taken amateur grading exams at the Central Conservatory of Music. I also produce electronic musicğŸµ, but only at an amateur level, just for my own enjoyment.

- My favorite genre of games is rhythm games. Iâ€™m currently obsessed with the rhythm game *Maimai DX*.

#### è”ç³»æˆ‘ Contact<p id="contact-info"></p>

- If you'd like to engage in a discussion or collaborate, feel free to contact me via email at any time! ğŸ¥°ğŸ¥°ğŸ¥°

- âœ‰ï¸ [zhaiwangyuxuan [at] bjtu.edu.cn](mailto:zhaiwangyuxuan@bjtu.edu.cn)
